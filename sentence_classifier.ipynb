{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-based Text Analytics of CyberSecurity Strategies\n",
    "Uses machine learning to calssify sentences from CyberSecurity documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These labels come from the headers in the cyberwellness profiles linked above**\n",
    "\n",
    "| Category               | Sub category |\n",
    "|------------------------| -------------|\n",
    "|LEGAL MEASURES          | CRIMINAL LEGISLATION, REGULATION AND COMPLIANCE|\n",
    "|TECHNICAL MEASURES      | CIRT, STANDARDS, CERTIFICATION|\n",
    "|ORGANIZATION MEASURES   | POLICY, ROADMAP FOR GOVERNANCE, RESPONSIBLE AGENCY, NATIONAL BENCHMARKING|\n",
    "|CAPACITY BUILDING       | STANDARDISATION DEVELOPMENT, MANPOWER DEVELOPMENT, PROFESSIONAL CERTIFICATION, AGENCY CERTIFICATION|\n",
    "|COOPERATION             | INTRA-STATE COOPERATION, INTRA-AGENCY COOPERATION, PUBLIC SECTOR PARTNERSHIP,  INTERNATIONAL COOPERATION|\n",
    "|CHILD ONLINE PROTECTION | NATIONAL LEGISLATION,  UN CONVENTION AND PROTOCOL, INSTITUTIONAL SUPPORT, REPORTING MECHANISM|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'Country': u'Jordan',\n",
      "  u'sentence': u'However, these approaches: are generally basic; not systematic; subjective; have no clear definition or boundaries, are not thorough; do not meet international standards; and do not deal effectively with threats emerging from cyberspace.',\n",
      "  u'sentence_id,': u'ff30d97ab4',\n",
      "  u'tag': [{u'category': u'technical measures',\n",
      "            u'subcategory': [u'standards']}]},\n",
      " {u'Country': u'Jordan',\n",
      "  u'sentence': u'Strategies and policies developed by the private sector should augment, comply, and be consistent with this strategy.',\n",
      "  u'sentence_id,': u'e50e3676b6',\n",
      "  u'tag': [{u'category': u'organization measures',\n",
      "            u'subcategory': [u'policy']}]},\n",
      " {u'Country': u'Jordan',\n",
      "  u'sentence': u'security policy and role-based security responsibilities will have a higher rate of success in protecting critical information.',\n",
      "  u'sentence_id,': u'ddd832b614',\n",
      "  u'tag': [{u'category': u'organization measures',\n",
      "            u'subcategory': [u'policy']}]},\n",
      " {u'Country': u'Jordan',\n",
      "  u'sentence': u'Develop National Information Security Standards and Policies An authorized government entity, National Information Assurance and Security Agency (NIACSA) (Section 5), will develop and or customize nationwide cyberspace security overarching standards considering current The efforts of implementing nationwide overarching standards and policies will be assigned or managed by NIACSA (Section 5).',\n",
      "  u'sentence_id,': u'b8ea57d517',\n",
      "  u'tag': [{u'category': u'technical measures',\n",
      "            u'subcategory': [u'standards']},\n",
      "           {u'category': u'organization measures',\n",
      "            u'subcategory': [u'policy']}]}]\n"
     ]
    }
   ],
   "source": [
    "# Opens training data stored as Json and converts to Python list\n",
    "with open('results_concatenated.json') as f:    \n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splits data into 3 parts, IDs, sentences, and tags\n",
    "\n",
    "# Optional\n",
    "sentence_ids = []\n",
    "\n",
    "# Lexicons created from sentences will be inputs\n",
    "sentences  = []\n",
    "\n",
    "# Tags will be outputs\n",
    "tags = []\n",
    "\n",
    "for input_val in data:\n",
    "    sentence_ids.append(input_val[u'sentence_id,'])\n",
    "    sentences.append(input_val[u'sentence'].encode(\"utf-8\"))\n",
    "    tags.append(input_val[u'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
