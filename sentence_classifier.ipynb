{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-based Text Analytics of CyberSecurity Strategies\n",
    "Uses machine learning to calssify sentences from CyberSecurity documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These labels come from the headers in the cyberwellness profiles linked above**\n",
    "\n",
    "| Category               | Sub category |\n",
    "|------------------------| -------------|\n",
    "|LEGAL MEASURES          | CRIMINAL LEGISLATION, REGULATION AND COMPLIANCE|\n",
    "|TECHNICAL MEASURES      | CIRT, STANDARDS, CERTIFICATION|\n",
    "|ORGANIZATION MEASURES   | POLICY, ROADMAP FOR GOVERNANCE, RESPONSIBLE AGENCY, NATIONAL BENCHMARKING|\n",
    "|CAPACITY BUILDING       | STANDARDISATION DEVELOPMENT, MANPOWER DEVELOPMENT, PROFESSIONAL CERTIFICATION, AGENCY CERTIFICATION|\n",
    "|COOPERATION             | INTRA-STATE COOPERATION, INTRA-AGENCY COOPERATION, PUBLIC SECTOR PARTNERSHIP,  INTERNATIONAL COOPERATION|\n",
    "|CHILD ONLINE PROTECTION | NATIONAL LEGISLATION,  UN CONVENTION AND PROTOCOL, INSTITUTIONAL SUPPORT, REPORTING MECHANISM|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using nltk for the first time, uncomment the following lines and run cell.\n",
    "# nltk.download must only be downloaded once\n",
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 3\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "The following cells read in training samples from a json file, create a lexicon from it, create arrays that store the number of occurences of each word in the lexicon, and serialize the generated list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'Country': u'Jordan',\n",
      "  u'sentence': u'However, these approaches: are generally basic; not systematic; subjective; have no clear definition or boundaries, are not thorough; do not meet international standards; and do not deal effectively with threats emerging from cyberspace.',\n",
      "  u'sentence_id,': u'ff30d97ab4',\n",
      "  u'tag': [{u'category': u'technical measures',\n",
      "            u'subcategory': [u'standards']}]},\n",
      " {u'Country': u'Jordan',\n",
      "  u'sentence': u'Strategies and policies developed by the private sector should augment, comply, and be consistent with this strategy.',\n",
      "  u'sentence_id,': u'e50e3676b6',\n",
      "  u'tag': [{u'category': u'organization measures',\n",
      "            u'subcategory': [u'policy']}]},\n",
      " {u'Country': u'Jordan',\n",
      "  u'sentence': u'security policy and role-based security responsibilities will have a higher rate of success in protecting critical information.',\n",
      "  u'sentence_id,': u'ddd832b614',\n",
      "  u'tag': [{u'category': u'organization measures',\n",
      "            u'subcategory': [u'policy']}]}]\n"
     ]
    }
   ],
   "source": [
    "# Opens training data stored as Json and converts to Python list\n",
    "with open('results_concatenated.json') as f:    \n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples is 2045 \n",
      "\n",
      "First example is \n",
      "X: However, these approaches: are generally basic; not systematic; subjective; have no clear definition or boundaries, are not thorough; do not meet international standards; and do not deal effectively with threats emerging from cyberspace. \n",
      "\n",
      " y: [{u'category': u'technical measures', u'subcategory': [u'standards']}]\n"
     ]
    }
   ],
   "source": [
    "# Splits data into 3 parts, IDs, sentences, and tags\n",
    "\n",
    "# For testing purposes\n",
    "sentence_ids = []\n",
    "\n",
    "# Lexicons created from sentences will be inputs\n",
    "sentences  = []\n",
    "\n",
    "# Tags will be outputs\n",
    "tags = []\n",
    "\n",
    "for input_val in data:\n",
    "    sentence_ids.append(input_val[u'sentence_id,'])\n",
    "    sentences.append(input_val[u'sentence'])\n",
    "    tags.append(input_val[u'tag'])\n",
    "\n",
    "print(\"Number of training examples is {} \\n\".format(len(sentences)))\n",
    "print(\"First example is \\nX: {} \\n\\n y: {}\".format(sentences[0], tags[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates lexicon (list of unique words) from all training samples\n",
    "def create_lexicon(sentences):\n",
    "    lexicon = []\n",
    "    for sentence in sentences:\n",
    "        for word in word_tokenize(sentence):\n",
    "            root = lemmatizer.lemmatize(word.lower()).encode('utf-8')\n",
    "            if len(root) > 1 and root not in stop and root not in lexicon:\n",
    "                lexicon.append(root)\n",
    "    \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates 2D array containing number of occurences of each word in lexicon in each sample\n",
    "def produce_X(sentences, lexicon):\n",
    "    X = []\n",
    "    for sentence in sentences:\n",
    "        X_sample = [0 for _ in lexicon]\n",
    "        for word in word_tokenize(sentence):\n",
    "            root = lemmatizer.lemmatize(word.lower()).encode('utf-8')\n",
    "            if root in lexicon:\n",
    "                X_sample[lexicon.index(root)] += 1\n",
    "        \n",
    "        X.append(X_sample)\n",
    "    \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['however', 'approach', 'generally', 'basic', 'systematic', 'subjective']\n"
     ]
    }
   ],
   "source": [
    "sample_lexicon = create_lexicon(sentences)\n",
    "pprint(sample_lexicon[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = produce_X(sentences, sample_lexicon)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pickles features generated for reuse\n",
    "\n",
    "with open('sample_X.npy', 'wb') as f:\n",
    "    np.save(f, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories (index 0-5)\n",
    "0. LEGAL MEASURES\n",
    "1. TECHNICAL MEASURES\n",
    "2. ORGANIZATION MEASURES\n",
    "3. CAPACITY BUILDING\n",
    "4. COOPERATION\n",
    "5. CHILD ONLINE PROTECTION\n",
    "\n",
    "> Categories will be stored as a 1D array with each number corresponding to a category listed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary stores label names and corresponding index to be turned on in the one hot vector.\n",
    "category_dict = {\n",
    "    u'LEGAL MEASURES' : 0,\n",
    "    u'TECHNICAL MEASURES' : 1,\n",
    "    u'ORGANIZATION MEASURES' : 2,\n",
    "    u'CAPACITY BUILDING' : 3,\n",
    "    u'COOPERATION' : 4,\n",
    "    u'CHILD ONLINE PROTECTION' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_y(tags):\n",
    "    return np.array([category_dict[tag[0][u'category'].upper()] for tag in tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ..., 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "y = produce_y(tags)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tags.npy', 'wb') as f:\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensorflow Boilerplate\n",
    "To simplify the Tensorflow code, we will define a set of functions to delare variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name=\"weight_variable\"):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name=\"bias_variable\"):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(X, W, b, name='fc'):\n",
    "    with tf.name_scope(name):\n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        \n",
    "        activation = tf.nn.relu(tf.matmul(X, W) + b)\n",
    "        tf.summary.histogram('activation', activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Now that the data has been processed it is now time to load the data and fit a model to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample_X.npy\",\"rb\") as f:\n",
    "    X = np.load(f)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ..., 2 1 2]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with open(\"tags.npy\",\"rb\") as f:\n",
    "    y = np.load(f)\n",
    "\n",
    "    print(y)\n",
    "    print(0 in y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n"
     ]
    }
   ],
   "source": [
    "print(list(y).index(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_options = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(vector):\n",
    "    def hot_or_not(i, j):\n",
    "        return 1 if i == j else 0\n",
    "    return np.array([[int(hot_or_not(i, j)) for j in range(number_of_options)] for i in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(X, y, batch_size=100):\n",
    "    n_batches = len(X) / batch_size\n",
    "    \n",
    "    for batch in range(n_batches):\n",
    "        start = (batch * batch_size)\n",
    "        end = start + batch_size if start + batch_size < len(X) else len(X) - 1\n",
    "        yield X[start:end], y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[1, 2], [2, 4]], [[0, 1], [2, 0]]), ([[3, 1]], [[0, 3]])]\n"
     ]
    }
   ],
   "source": [
    "print(list(next_batch([[1,2],[2,4],[3,1],[4,3]], [[0,1],[2,0],[0,3],[0,4]], batch_size=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Constructing the Model\n",
    "Now we can create a neural network to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexicon_size = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_placeholder = tf.placeholder(tf.float32, [None, lexicon_size], name=\"X\")\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, number_of_options], name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = weight_variable([lexicon_size, 200])\n",
    "b1 = bias_variable([200])\n",
    "\n",
    "model = fc_layer(X_placeholder, w1, b1, name='fc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2 = weight_variable([200, 500])\n",
    "b2 = bias_variable([500])\n",
    "\n",
    "model = fc_layer(model, w2, b2, name='fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w3 = weight_variable([500, 200])\n",
    "b3 = bias_variable([200])\n",
    "\n",
    "model = fc_layer(model, w3, b3, name='fc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3 = weight_variable([200, number_of_options])\n",
    "b3 = bias_variable([number_of_options])\n",
    "\n",
    "y_predicted = tf.matmul(model, w3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(labels=y_placeholder, logits=y_predicted))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predicted,1), tf.argmax(y_placeholder,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Splitting up the Data\n",
    "Now we have to split up the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " ..., \n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0]]\n",
      "1840\n",
      "1840\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.9\n",
    "y_hot = one_hot(y)\n",
    "print(y_hot)\n",
    "\n",
    "X_split_index = int(len(X)*TEST_SIZE)\n",
    "y_split_index = int(len(y_hot)*TEST_SIZE)\n",
    "\n",
    "X_train, X_test = X[:X_split_index], X[X_split_index:]\n",
    "y_train, y_test = y_hot[:y_split_index], y_hot[y_split_index:]\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session starting\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.492934793234\n",
      "Test accuracy 0.56097561121\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.518478274345\n",
      "Test accuracy 0.517073154449\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.441847831011\n",
      "Test accuracy 0.375609755516\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.435869574547\n",
      "Test accuracy 0.390243887901\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.435326099396\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.433152168989\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.432065218687\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.432065218687\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.432065218687\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n",
      "batch number: 16\n",
      "batch number: 17\n",
      "Train accuracy 0.431521743536\n",
      "Test accuracy 0.370731711388\n",
      "batch number: 0\n",
      "batch number: 1\n",
      "batch number: 2\n",
      "batch number: 3\n",
      "batch number: 4\n",
      "batch number: 5\n",
      "batch number: 6\n",
      "batch number: 7\n",
      "batch number: 8\n",
      "batch number: 9\n",
      "batch number: 10\n",
      "batch number: 11\n",
      "batch number: 12\n",
      "batch number: 13\n",
      "batch number: 14\n",
      "batch number: 15\n"
     ]
    }
   ],
   "source": [
    "    with tf.Session() as sess:\n",
    "        print(\"Session starting\")\n",
    "        \n",
    "        merged_summary = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(\"/tmp/cyber/3\")\n",
    "        writer.add_graph(sess.graph)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(1000):\n",
    "            epoch_loss = 0\n",
    "            avg_cost = 0.0\n",
    "            for i, (batch_X, batch_y) in enumerate(next_batch(X_train, y_train)):\n",
    "                print('batch number: {}'.format(i))\n",
    "                # print(\"\\nbatch_X\\n {}\\n\\nbatch_y\\n {}\\n\".format(batch_X, batch_y))\n",
    "                sess.run(optimizer, feed_dict={X_placeholder: batch_X, y_placeholder: batch_y})\n",
    "                \n",
    "                s = sess.run(merged_summary, feed_dict={X_placeholder: batch_X, y_placeholder: batch_y})\n",
    "                writer.add_summary(s, i)\n",
    "                \n",
    "            print(\"Train accuracy {}\".format(accuracy.eval({X_placeholder: X_train, y_placeholder: y_train})))\n",
    "            print(\"Test accuracy {}\".format(accuracy.eval({X_placeholder: X_test, y_placeholder: y_test})))\n",
    "\n",
    "        print(\"Final Test accuracy {}\".format(accuracy.eval({X_placeholder: X_test, y_placeholder: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
